---
layout: splash
permalink: /
title: A Smart Camera for the Intelligent Edge
header:
  overlay_color: "#5e616c"
  overlay_image: /assets/images/node-graphic.png
  image: /assets/images/camera-render-transparent-small.png
  alt: "Picture of the Vision AI DevKit camera hardware"
  actions:
    - label: "Back in Stock! - Order Now <i class='fas fa-chevron-right'></i>"
      url: "https://www.arrow.com/en/products/eic-ms-vision-500/einfochips-limited"
excerpt: >
  Jumpstart your Azure vision machine learning journey
VAIDK_More:
  - title: "Start fast"
    excerpt: |
      [Get up and running in minutes](https://aka.ms/VAIDKGetStarted-Landing/), regardless of your current skill level with vision machine learning. Connect your camera to Azure IoT Hub that controls the network traffic between the device and the cloud, and see the camera in action by running a default Vision AI module that recognizes 183 different objects.
      # Build fast
      * New to Vision ML? Start building a vision model by uploading and tagging pictures, letting [Azure Custom Vision Service](https://azure.github.io/Vision-AI-DevKit-Pages/docs/Tutorial-HOL_Using_the_VisionSample/){:target="_blank"} do the heavy lifting.
      * Experienced with vision ML? Use [Jupyter notebooks](https://azure.github.io/Vision-AI-DevKit-Pages/docs/jupyter/){:target="_blank"} and [Visual Studio Code](https://azure.github.io/Vision-AI-DevKit-Pages/docs/SetUp_VS_Code/) to create and train custom vision models using Azure Machine Learning (AML). AML services enable you to prepare data and train models. You can then convert the trained model to the custom DLC format and package it into an IoT Edge module to deploy to the Vision AI Dev Kit.
      
      # Deploy Fast
      [Azure IoT Hub](https://docs.microsoft.com/en-us/azure/iot-hub/) can push your containerized vision ML models and other modules to the Vision AI DevKit with ease, whether the camera is on your desk or in another country.   

      # Join the Community
      Get help and help others with vision ML projects by joining our [Tech Community](https://aka.ms/VAIDK-IoTTechCommunity){:target="_blank"} and [Gitter](https://aka.ms/VAIDKGitter-Landing/){:target="_blank"}.
      # Build the intelligent edge
      As an [Intelligent Edge device](https://azure.microsoft.com/en-us/overview/future-of-cloud/){:target="_blank"}, the Vision AI DevKit does inferences and runs containerized Azure services locally in the device. Moving these workloads to the edge of the network means vision ML inferencing work requires less cloud interaction while also enabling quick reaction to local events, allowing operation during extended offline periods.

      # Get Support

      Get quick answers to your questions by asking them [here](https://aka.ms/VAIDKGetHelp-Landing/).

      If you purchased your camera from Arrow, you are also entitled to one hour of complimentary support from eInfochips. This support includes:
      * Quick start guidance for connectivity to Azure IoT Hub
      * Guidance to create and deploy a custom vision AI model using custom vision services 
      * Guidance for setting up Visual Studio Code environment for Vision ML kit
      * Setup for Azure account (if not available)
      * Guidance to change personal connectivity on VAIDK i.e. Wi-Fi access / passphrase changes
      * Guidance for upgrade and install latest firmware build for VAIDK, followed by reboot procedure
      * Factory default settings and reboot procedures.

      To request support from eInfoChips, go [here](https://www.einfochips.com/partnerships-and-alliances/digital-partnerships/microsoft/microsoft-ai-vision-kit/).


  - title: "What's New?"
    excerpt: |
      <html><table>
      <tr><td>
      <a href="docs/community_project02/">
      <img src='assets/images/safety.png' alt='Workplace Safety Model' style='max-width: 320px'></a>
      </td><td><font size="4"><b>
      Partnering with Purdue</b></font>
      <br> <font size="3">
      MS partners with Purdue University to publish a project on the Workplace Safety (PPE) model using the Vision AI Dev Kit and Custom Vision. Read the published article <a href="https://www.sciencedirect.com/science/article/pii/S2351978920310556">here</a>
      </font>
      </td></tr>
      <html><table><tr><td>
      <iframe src="https://channel9.msdn.com/Shows/Internet-of-Things-Show/Deploying-Models-with-Vision-AI-DevKit/player" width="320px"  allowFullScreen frameBorder="0" title="Use Audio on the Vision AI DevKit - Microsoft Channel 9 Video"></iframe>
      </td><td><font size="4"><b>
      Deploying Models</b></font>
      <br> <font size="3">
      Mahesh is back to show us how you can train and deploy new AI models on the device in a matter of minutes. Watch on <a href="https://channel9.msdn.com/Shows/Internet-of-Things-Show/Deploying-Models-with-Vision-AI-DevKit">Channel 9</a>
      </font>
      </td></tr>
      <html><table><tr><td>
      <iframe src="https://channel9.msdn.com/Shows/Internet-of-Things-Show/Use-Audio-on-the-Vision-AI-DevKit/player" width="320px"  allowFullScreen frameBorder="0" title="Use Audio on the Vision AI DevKit - Microsoft Channel 9 Video"></iframe>
      </td><td><font size="4"><b>
      Using Audio</b></font>
      <br> <font size="3">
      Learn how to use audio from the Vision AI DevKit as input data for IoT solutions. Watch on <a href="https://channel9.msdn.com/Shows/Internet-of-Things-Show/Use-Audio-on-the-Vision-AI-DevKit">Channel 9</a>
      </font>
      </td></tr>
      <tr><td>
      <iframe src="https://channel9.msdn.com/Shows/Internet-of-Things-Show/Unboxing-the-Vision-AI-DevKit/player" width="320px"  allowFullScreen frameBorder="0" title="Unboxing the Vision AI DevKit - Microsoft Channel 9 Video"></iframe>
      </td><td><font size="4"><b>
      Unboxing!</b></font>
      <br> <font size="3">
      See how easy it is to set up the Vision AI Developer Kit and connect it to Azure services! Watch on <a href="https://channel9.msdn.com/Shows/Internet-of-Things-Show/Unboxing-the-Vision-AI-DevKit">Channel 9</a>
      </font>
      </td></tr>
      <tr><td>
      <a href="https://microsoft.github.io/ai-at-edge/">
      <img src='assets/images/WN_aiatedge.PNG' alt='AI@Edge community' style='max-width: 320px'></a>
      </td><td><font size="4"><b>
      Visit the AI@Edge portal!</b></font>
      <br> <font size="3">
      Microsoft is launching an AI@Edge community. Find hardware, ML and cloud resources you need to create solutions using intelligence at the edge
      </font>
      </td></tr>
      </table></html>


advantages:
  - video_path: https://easstandardhosting123.blob.core.windows.net/asset-0a1504fe-8b97-4e8f-a312-2a5eef36c891/Vision_AI_101418.mp4?sv=2015-07-08&sr=c&si=1da79a8d-775c-4a56-af1a-173c36a1823b&sig=W7ACJX%2F0FrlqxYg7TlPfjojO3Ajf%2FiHy7eW4%2FfgK%2BAk%3D&st=2018-10-25T01%3A49%3A06Z&se=2118-10-25T01%3A49%3A06Z
    video_poster: /assets/images/Video_poster.png

  - title: 
    excerpt: >
        <img src='assets/images/msft-logo-gray.svg' alt='Microsoft' style='max-width: 135px'><br>

        An Azure IoT starter kit, the Vision AI DevKit can be used with models built and trained using the [Azure Machine Learning service](https://azure.microsoft.com/en-us/services/machine-learning-service/){:target="_blank"} and [CustomVision.ai](https://customvision.ai){:target="_blank"}. <br><br>

        <img src='assets/images/qualcomm-logo-blue.png' alt='Qualcomm' style='max-width: 125px'><br>

        The Vision AI DevKit features the [Qualcomm Visual Intelligence Platform](https://www.qualcomm.com/news/onq/2018/05/07/qualcomm-vision-intelligence-platform-microsoft-azure-bring-edge-ai-solution){:target="_blank"} for hardware acceleration of AI models to deliver superior inferencing performance.<br><br>

        <img src='assets/images/EIC-Logo-with-Tagline.png' alt='eInfoChips' style='max-width: 160px'><br>

        eInfoChips (an Arrow Company) is a leading provider of design services in vision based AI and the Edge2Cloud services.  With 24+ years of full spectrum product engineering expertise and a 2000+ member team skilled at engineering products across Silicon – Hardware – Software – Cloud spectrum,  helping companies realize their connected product roadmaps in partnership with Qualcomm and Microsoft.

tech_specs:
  - title: "<img src='assets/images/Peabody_spec_image.png' alt='Vision AI DevKit device image'>"

  - title: "<img src='assets/images/Peabody_spec_image2.png' alt='Vision AI DevKit specs'>"

whatsnew:
  content:
  - title: AI@Edge
whatsnew_links:
  content:
    - image_path: assets/images/WN_aiatedge.PNG
      alt: "Join the AI@Edge community"
      title: "Join the AI@Edge community"
      excerpt: Find the resources you need to create solutions using intelligence at the edge
      url: "https://aka.ms/aiatedge"
    - image_path: /assets/images/WN_faceapi.PNG
      alt: "Use Microsoft's Face API"
      title: "Use Microsoft's Face API"
      excerpt: "Check out community project using Microsoft's face API to recognize facial characteristics"
      url: "/docs/projects/community_project05/"
    - image_path: /assets/images/WN_audio.PNG
      alt: "Enable audio for Vision AI Dev Kit"
      title: "Enable audio for Vision AI Dev Kit"
      excerpt: "See community project for enabling audio for Vision AI Developer Kit"
      url: "/docs/projects/community_project03/"

---

<div class="feature__outer_wrapper">
{% include feature_row id="VAIDK_More" type="dual" %}
</div>

<!-- {% include feature_row_1 id="whatsnew_links" %} -->

<div class="feature__outer_wrapper">
{% include feature_row id="advantages" type="dual" %}
</div>

<h2 style="text-align: center">Technical Specifications</h2>

<div class="feature__outer_wrapper">
{% include feature_row id="tech_specs" type="dual" %}
</div>

<!--       # <tr><td>
      # <a href="/Vision-AI-DevKit-Pages/docs/community_project03/">
      # <img src='assets/images/WN_audio.PNG' alt='Audio' style='max-width: 320px'></a>
      # </td><td><font size="4"><b>
      # Train audio ML model for Vision AI Developer Kit</b></font>
      # <br><font size="3">
      # Vision AI Developer Kit comes also with microphones! Record with Vision AI Dev Kit, then train your AI model using the recordings and deploy it to the camera.
      # </font></td></tr></table></html> -->